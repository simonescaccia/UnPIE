# Training params
learning_rates: '0.03,0.01,0.007' # optimizer learning rates
# learning_rates: '0.003'
weight_decay: 0.0001 # loss function weight decay
instance_t: 0.07 # temperature for contrastive loss
batch_size: 32 # training batch size
inference_batch_size: 32 # val/test batch size
inference_num_clips: 5 # number of clips to sample from each video
clstr_update_per_epoch: 10 # number of cluster updates per epoch
fre_plot_clusters: 50 # frequency to plot clusters (epochs)
kNN_inference: 100 # number of nearest neighbors to consider
instance_k: 0 # background neighbors to sample. If 0, all training samples are considered
fre_save_model: 1 # frequency to save model checkpoint (epochs)
fre_valid: 1 # frequency to validate model (epochs)
num_classes: 2 # number of different clusters
train_steps: 'IR,LA' # training steps
IR:
  task: 'IR' # task name
  lr_boundaries: null # learning rate boundaries
  train_num_workers: 1 # number of workers for training data loader
  val_num_workers: 1 # number of workers for validation data loader
  train_num_epochs: 0 # number of training epochs
  load_task: null # load task
  load_step: null # load step
LA:
  task: 'LA'
  lr_boundaries: '2800,2900'
  # lr_boundaries: null
  train_num_workers: 1
  val_num_workers: 1
  train_num_epochs: 500
  load_task: 'IR'

# Data preprocessing params
data_sets: 'all' # data sets to use (small, all)
feature_extractor: 'vgg16' # feature extractor to use (vgg16, efficientnetb3)
edge_importance: True # weights for edges in the graph.
edge_weigths: 'norm_compl' # Choose between False, no_norm, norm, norm_compl, compl
num_frames: 15 # number of frames in each clip
img_height: 1080 # video frame height
img_width: 1920 # video frame width

# Network params
channel_dim: 512 # output shape of vgg feature extractor
# channel_dim: 1536 # output shape of efficientnetB3 feature extractor
middle_dim: 256 # middle layer dimension in the unpie network
gcn_dim: 128 # final gcn layer dimension
num_input_layers: 3 # number of input layers in the unpie network
num_middle_layers: 3 # number of middle layers in the unpie network
num_gcn_final_layers: 3 # number of final gcn layers in the unpie network
scene_gcn_dim: 32 # final scene embedding dimension
drop_tcn: 0.2 # dropout rate for temporal convolutional network
drop_conv: 0.2 # dropout rate for graph convolutional network
is_scene: True # whether to use scene embeddings
share_edge_importance: False # whether to share edge importance weights between scene and node gcns

# Log files
train_log_file: 'log.txt' # training log file
val_log_file: 'val_log.txt' # validation log file
val_prediction_file: 'val_predictions.txt' # validation prediction file
test_log_file: 'test_log.txt' # test log file
cache_dir: 'checkpoints' # directory to save model checkpoints
plot_dir: 'cluster_plots' # directory to save plots
